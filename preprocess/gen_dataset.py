'''
    generate dataset from RadGraph for GraphGen network training
    input: mapping file of OBS and ANAT, RadGraph training
    output: dataset json file containing [['triplet_relations':[1,3,2] 'cls':[OBS,ANAT]]]
    steps:
        1. extract all 'tokens' in class OBS and class ANAT from the file, and write them into a new json file
        2. iterate all studies again, to convert the tokens into non-sensitive numbers
        3. output the final json file
'''


import json
from collections import Counter

### globally define splite ###
splite = "train"
with open('D:/studium/MIML/radgraph/radgraph/' + splite + '.json', 'r') as f:
    data = json.load(f)

#splite_open = splite

# if splite == "train":
#     splite_open = "train"
# if splite == 'dev':
#     splite_open = 'dev'
# if splite == 'extend':
#     splite_open = 'extend+train_add_sug'
# if splite == 'baseline':
#     splite_open = 'pre_baseline'
# if splite == 'train_all':
#     splite_open = 'MIMIC-CXR_graphs'
# if splite == 'chexpert':
#     splite_open = 'CheXpert_graphs'
# if splite == 'baseline_chex':
#     splite_open = 'pred_chexpert_baseline'

### Open the files with tokens generated by Radgraph
# if splite_open == "out_mimic":
#     with open('D:/studium/MIML/radgraph/GraphGen/baseline/out_mimic.json', 'r') as f:
#         data = json.load(f)
# else:



### some helper functions

def mapping_name(dict,value):
    # mapping the words given dictionary
    for key,ls in dict.items():
        if value in ls:
            return key
    # if cant find the key
    return None

def mapping_accoring_to_label(mapping_subpart,mapping_observation,label,name):
    # given a word and its label, output the final token
    if label.startswith('OBS'):
        return mapping_name(mapping_observation,name)
    if label.startswith('ANAT'):
        return mapping_name(mapping_subpart,name)

def save_tokens_to_template(output_dict,label,name):
    # save the related tokens in a triplet into a dictionary
    if label.startswith('OBS'):
        output_dict['OBS'].append(name)
    if label.startswith('ANAT'):
        output_dict['ANAT'].append(name)

    return output_dict

def save_tokens_to_dataset(tri_ls,lbl_ls,study_dict):
    # save the related tokens in a triplet into a dictionary
    study_dict["triplet"].append(tri_ls)
    study_dict["labels"].append(lbl_ls)


    return study_dict

def tokens_to_number(tri_1,tri_1_lbl,tri_3,tri_3_lbl,rlt,study_dict):
    # convert tokens into non-sensitive idx

    tri_1_idx = obs_anat_ls.index(tri_1)
    lbl_ls_1 = tri_1_lbl
    tri_3_idx = obs_anat_ls.index(tri_3)
    lbl_ls_3 = tri_3_lbl

    idx = [i for i, x in enumerate(study_dict["tokens"]) if x == tri_1_idx]
    for id in idx:
        if study_dict["labels"][id][0] == lbl_ls_1[0]:
            tri_1_idx = id

    idx = [i for i, x in enumerate(study_dict["tokens"]) if x == tri_3_idx]
    for id in idx:
        if study_dict["labels"][id][0] == lbl_ls_3[0]:
            tri_3_idx = id

    tri_2_idx = rlt_ls.index(rlt)
    study_dict["edges"].append([tri_1_idx,tri_3_idx,tri_2_idx])

    return study_dict


def save_tokens_lables(tri_1,tri_1_lbl,tri_3,tri_3_lbl,obs_anat_ls,study_dict):
    #save tokens and lables
    flag_contain_tri_1 = False
    flag_contain_tri_3 = False

    ### produce ds for matcher 1
    tri_1_idx = obs_anat_ls.index(tri_1)
    lbl_ls_1 = tri_1_lbl
    tri_3_idx = obs_anat_ls.index(tri_3)
    lbl_ls_3 = tri_3_lbl

    idx = [i for i, x in enumerate(study_dict["tokens"]) if x == tri_1_idx]
    for id in idx:
        if study_dict["labels"][id][0] == lbl_ls_1[0]:
            flag_contain_tri_1 = True
    if not flag_contain_tri_1:
        study_dict["tokens"].append(tri_1_idx)
        study_dict["labels"].append(lbl_ls_1)

    idx = [i for i, x in enumerate(study_dict["tokens"]) if x == tri_3_idx]
    for id in idx:
        if study_dict["labels"][id][0] == lbl_ls_3[0]:
            flag_contain_tri_3 = True
    if not flag_contain_tri_3:
        study_dict["tokens"].append(tri_3_idx)
        study_dict["labels"].append(lbl_ls_3)


    return study_dict


### load the mappings
with open('D:/studium/MIML/radgraph/radgraph/mapping_delete_meaningless.json', 'r') as f:
    mapping_dict = json.load(f)
mapping_subpart = mapping_dict["mapping_subpart"]
mapping_observation = mapping_dict["mapping_observation"]
mapping = mapping_dict["mapping_organs"]


###############################################################################################################
### step 1: extract all 'tokens' in class OBS and class ANAT from the file, and write them into a new json file
###############################################################################################################
# always use train.json to generate the template
# with open('D:/studium/MIML/radgraph/radgraph/train.json', 'r') as f:
#     data = json.load(f)
#
# output_dict = {"OBS":[],
#                "ANAT":[],
#                "total":[]}
# for key in data.keys():  # key : "p18/p18004941/s58821758.txt"
#     #print(key)
#     new_dict = data[key]
#     entities = new_dict['entities']
#     for new_key in entities.keys():
#         entity = entities[new_key]      #"tokens": "clear", "label": "OBS-DP", "start_ix": 38, "end_ix": 38, "relations": [["located_at", "1"]]
#         relations = entity['relations']
#         if len(relations):              # only care about the tokens with 'relations'
#             for i in range(len(relations)):
#                 #print(relations[i][0])
#                 tri_3 = entities[relations[i][1]]["tokens"]   #relations[i][1] is "1" in this case
#                 tri_3_lbl = entities[relations[i][1]]['label']
#                 tri_1 = entity["tokens"]
#                 #print("ok")
#                 #print(tri_1, tri_3)
#                 tri_3 = mapping_accoring_to_label(mapping_subpart,mapping_observation,
#                                                   tri_3_lbl,tri_3.lower())
#                 tri_1 = mapping_accoring_to_label(mapping_subpart, mapping_observation,
#                                                   entity['label'], tri_1.lower())
#                 #print(tri_1,tri_3)
#                 if tri_1 and tri_3: # if both tokens are existing in lib
#                     output_dict = save_tokens_to_template(output_dict, entity['label'],tri_1)
#                     output_dict = save_tokens_to_template(output_dict, tri_3_lbl, tri_3)
#
#
#
#         # A function that could filter out the low_freq items:
#         # set the nr >=1, then all items are included
# for key_organ in output_dict.keys():
#         ls = output_dict[key_organ]
#         ls_filterd = []
#         ### Count the nr of each items ###
#         result = Counter(ls)
#         for dis,nr in result.items():
#             if nr >= 1:
#                 ls_filterd.append(dis)
#         ls = ls_filterd
#         output_dict[key_organ] = ls
# #output file
# obs_anat_ls = output_dict["OBS"].copy()
# obs_anat_ls.extend(output_dict["ANAT"])
# obs_anat_ls = list(set(obs_anat_ls))
# output_dict["total"] = obs_anat_ls
# a_file = open("D:/studium/MIML/radgraph/GraphGen/OBS_ANAT_list.json", "w")
# json.dump(output_dict, a_file)
# a_file.close()

###############################################################################################################
### step 2: iterate the dataset again, and convert the words into non-sensitive numbers, write into a dictionary
###############################################################################################################
with open("D:/studium/MIML/radgraph/GraphGen/OBS_ANAT_temp.json", 'r') as f:
    data_ls = json.load(f)
obs_ls = data_ls["OBS"]
anat_ls = data_ls["ANAT"]
obs_anat_ls = data_ls["total"]
print(len(obs_anat_ls))   #229
#print(obs_anat_ls)



dataset_dict = {}

rlt_ls = ["modify","located_at","suggestive_of"]

for key in data.keys():  # key : "p18/p18004941/s58821758.txt"
    #print(key)
    new_dict = data[key]
    study_dict = {"tokens": [],
                  "labels": [],
                  "edges": []}
    entities = new_dict['entities']
    for new_key in entities.keys():
        entity = entities[new_key]      #"tokens": "clear", "label": "OBS-DP", "start_ix": 38, "end_ix": 38, "relations": [["located_at", "1"]]
        relations = entity['relations']
        if len(relations):              # only care about the tokens with 'relations'
            for i in range(len(relations)):
                #print(relations[i][0])
                tri_3 = entities[relations[i][1]]["tokens"]   #relations[i][1] is "1" in this case
                tri_3_lbl = entities[relations[i][1]]['label']
                tri_1 = entity["tokens"]
                tri_1_lbl = entity['label']
                rlt = relations[i][0]
                #print("ok")
                #print(tri_1, tri_3)
                tri_3 = mapping_accoring_to_label(mapping_subpart,mapping_observation,
                                                  tri_3_lbl,tri_3.lower())
                tri_1 = mapping_accoring_to_label(mapping_subpart, mapping_observation,
                                                  entity['label'], tri_1.lower())
                #print(tri_1,tri_3)
                if tri_1 and tri_3 and (tri_1 in obs_anat_ls) and (tri_3 in obs_anat_ls): # if both tokens are existing in lib
                    study_dict = save_tokens_lables(tri_1,tri_1_lbl,tri_3,tri_3_lbl,obs_anat_ls,study_dict) # firstly generate tokens and labels

    for new_key in entities.keys():
        entity = entities[
            new_key]  # "tokens": "clear", "label": "OBS-DP", "start_ix": 38, "end_ix": 38, "relations": [["located_at", "1"]]
        relations = entity['relations']
        if len(relations):  # only care about the tokens with 'relations'
            for i in range(len(relations)):
                # print(relations[i][0])
                tri_3 = entities[relations[i][1]]["tokens"]  # relations[i][1] is "1" in this case
                tri_3_lbl = entities[relations[i][1]]['label']
                tri_1 = entity["tokens"]
                tri_1_lbl = entity['label']
                rlt = relations[i][0]
                # print("ok")
                # print(tri_1, tri_3)
                tri_3 = mapping_accoring_to_label(mapping_subpart, mapping_observation,
                                                  tri_3_lbl, tri_3.lower())
                tri_1 = mapping_accoring_to_label(mapping_subpart, mapping_observation,
                                                  entity['label'], tri_1.lower())
                # print(tri_1,tri_3)
                if tri_1 and tri_3 and (tri_1 in obs_anat_ls) and (tri_3 in obs_anat_ls):  # if both tokens are existing in lib
                    edge_ls = tokens_to_number(tri_1,tri_1_lbl,tri_3,tri_3_lbl,rlt,study_dict)
    dataset_dict[key] = study_dict

print(len(dataset_dict))
a_file = open("D:/studium/MIML/radgraph/GraphGen/"+splite+"_exracted.json", "w")
json.dump(dataset_dict, a_file)
a_file.close()
print("finished")



